{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation data\n",
    "3/14/2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem =  arcpy.SpatialReference(\"USA Contiguous Albers Equal Area Conic USGS\")\n",
    "\n",
    "data_path = \"your_path\"\n",
    "results_path = \"your_results_path\"\n",
    "scratch_gdb = \"your_scratch_path\"\n",
    "\n",
    "# Local parcel data\n",
    "meck = os.path.join(data_path, \"city_buildings/Mecklenburg_NC/TaxData_2020.shp\")\n",
    "sacramento = os.path.join(data_path, \"city_buildings/Sacramento_CA/Parcels.shp\")\n",
    "miami = os.path.join(data_path, \"city_buildings/Miami_FL/parcels_with_landuse.gdb/parcels_with_landuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification functions\n",
    "def classify_sacramento(row, field_index):\n",
    "    residential_types = {\"Residential\"} \n",
    "    non_residential_types = {\"Agricultural\", \"Care / Health\", \"Church / Welfare\",\"Industrial\", \"Miscellaneous\", \"Office\", \"Public / Utilities\",\"Recreational\",\"Retail / Commercial\"}\n",
    "    return 1 if row[field_index] in residential_types else 0 if row[field_index] in non_residential_types else None\n",
    "    \n",
    "def classify_meck(input_shapefile, output_shapefile):\n",
    "    # Set up the environment\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    \n",
    "    # Define land use classifications\n",
    "    residential_types = {'Condo/Townhome', 'Multi-Family', 'Single-Family'}\n",
    "    non_residential_types = {'Commercial', 'Govt-Inst', 'Hotel/Motel', 'Office', 'Warehouse'}\n",
    "    \n",
    "    # Copy input shapefile to output location\n",
    "    print(\"Copying features...\")\n",
    "    arcpy.CopyFeatures_management(input_shapefile, output_shapefile)\n",
    "    \n",
    "    # Add the res_or_not field if it doesn't exist\n",
    "    if \"res_or_not\" not in [f.name for f in arcpy.ListFields(output_shapefile)]:\n",
    "        arcpy.AddField_management(output_shapefile, \"res_or_not\", \"SHORT\")\n",
    "    \n",
    "    # Get total count for progress bars\n",
    "    total_count = int(arcpy.GetCount_management(output_shapefile)[0])\n",
    "    \n",
    "    # Dictionary to store objectid -> list of all valid descproper values\n",
    "    objectid_descproper = {}\n",
    "    print(\"First pass: Collecting land use classifications for each objectid...\")\n",
    "    # Collect all unique descproper values per objectid\n",
    "    with arcpy.da.SearchCursor(output_shapefile, [\"objectid\", \"descproper\"]) as cursor:\n",
    "        with tqdm(total=total_count, desc=\"Scanning features\") as pbar:\n",
    "            for objectid, landuse in cursor:\n",
    "                if objectid not in objectid_descproper:\n",
    "                    objectid_descproper[objectid] = set()\n",
    "                # Include all values, even empty ones, but strip them\n",
    "                if landuse is not None:\n",
    "                    objectid_descproper[objectid].add(landuse.strip())\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Dictionary to store the best res_or_not value per objectid\n",
    "    objectid_res_or_not = {}\n",
    "    print(\"Assigning residential classifications...\")\n",
    "    # Determine the best classification per objectid\n",
    "    for objectid, landuse_values in tqdm(objectid_descproper.items(), desc=\"Processing classifications\"):\n",
    "        if any(lu in residential_types for lu in landuse_values):\n",
    "            objectid_res_or_not[objectid] = 1  # Residential\n",
    "        elif any(lu in non_residential_types for lu in landuse_values):\n",
    "            objectid_res_or_not[objectid] = 0  # Non-Residential\n",
    "        else:\n",
    "            objectid_res_or_not[objectid] = None  # Unclassified (NULL)\n",
    "    \n",
    "    print(\"Second pass: Updating dataset with classifications...\")\n",
    "    # Create a dictionary to store the best row for each objectid\n",
    "    best_rows = {}\n",
    "    \n",
    "    def is_better_row(current_descproper, current_classification, best_descproper, best_classification):\n",
    "        \"\"\"Helper function to determine if current row is better than the stored best row\"\"\"\n",
    "        # Normalize descproper values\n",
    "        current_descproper = current_descproper.strip() if current_descproper else \"\"\n",
    "        best_descproper = best_descproper.strip() if best_descproper else \"\"\n",
    "        \n",
    "        # If current is residential and best isn't, current wins\n",
    "        if current_classification == 1 and best_classification != 1:\n",
    "            return True\n",
    "            \n",
    "        # If both are residential or both are non-residential, prefer non-empty descproper\n",
    "        if current_classification == best_classification:\n",
    "            # If current is a valid non-residential type and best is empty/blank\n",
    "            if (current_descproper in non_residential_types and \n",
    "                (not best_descproper or best_descproper.isspace())):\n",
    "                return True\n",
    "            # If both are empty or both are non-empty, keep the existing one\n",
    "            return False\n",
    "            \n",
    "        # If current is non-residential and best is unclassified, current wins\n",
    "        if current_classification == 0 and best_classification is None:\n",
    "            return True\n",
    "            \n",
    "        # In all other cases, keep the existing best row\n",
    "        return False\n",
    "    \n",
    "    with arcpy.da.SearchCursor(output_shapefile, [\"objectid\", \"descproper\", \"SHAPE@\", \"OID@\"]) as cursor:\n",
    "        with tqdm(total=total_count, desc=\"Finding best rows\") as pbar:\n",
    "            for row in cursor:\n",
    "                objectid, descproper, shape, oid = row\n",
    "                current_classification = objectid_res_or_not.get(objectid)\n",
    "                \n",
    "                # Initialize best row if we haven't seen this objectid\n",
    "                if objectid not in best_rows:\n",
    "                    best_rows[objectid] = (oid, descproper, current_classification)\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Get the existing best row's information\n",
    "                best_oid, best_descproper, best_classification = best_rows[objectid]\n",
    "                \n",
    "                # Check if current row is better using our helper function\n",
    "                if is_better_row(descproper, current_classification, \n",
    "                               best_descproper, best_classification):\n",
    "                    best_rows[objectid] = (oid, descproper, current_classification)\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    print(\"Third pass: Applying final classifications and removing duplicates...\")\n",
    "    with arcpy.da.UpdateCursor(output_shapefile, [\"objectid\", \"res_or_not\", \"OID@\"]) as cursor:\n",
    "        with tqdm(total=total_count, desc=\"Finalizing features\") as pbar:\n",
    "            for row in cursor:\n",
    "                objectid, _, oid = row\n",
    "                if objectid in best_rows:\n",
    "                    best_oid, _, classification = best_rows[objectid]\n",
    "                    if oid == best_oid:\n",
    "                        row[1] = classification  # Update classification\n",
    "                        cursor.updateRow(row)\n",
    "                    else:\n",
    "                        cursor.deleteRow()  # Remove non-best rows\n",
    "                else:\n",
    "                    row[1] = None  # Set classification to NULL for any remaining rows\n",
    "                    cursor.updateRow(row)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    print(f\"Process completed successfully. Output saved to: {output_shapefile}\")\n",
    "    # Return count of residential parcels for verification\n",
    "    with arcpy.da.SearchCursor(output_shapefile, [\"res_or_not\"]) as cursor:\n",
    "        residential_count = sum(1 for row in cursor if row[0] == 1)\n",
    "    print(f\"Total residential parcels: {residential_count}\")\n",
    "\n",
    "def create_miami_parcels_w_lu(parcel_polygons, landuse_layer, output_fc, workspace):\n",
    "    \"\"\"\n",
    "    Samples land use data for parcels by converting parcels to points and sampling.\n",
    "    Uses file-based storage for temporary data and cursor-based joining for speed.\n",
    "    \n",
    "    Parameters:\n",
    "    parcel_polygons (str): Path to input parcel polygon feature class\n",
    "    landuse_layer (str): Path to land use polygon feature class\n",
    "    output_fc (str): Path to output feature class\n",
    "    workspace (str): Path to folder for temporary files\n",
    "    \"\"\"\n",
    "    import arcpy\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Set up environment\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    \n",
    "    # Generate timestamp for unique temporary file names\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Temporary feature classes in specified workspace\n",
    "    temp_points = os.path.join(workspace, f\"parcel_points_{timestamp}\")\n",
    "    temp_landuse = os.path.join(workspace, f\"landuse_projected_{timestamp}\")\n",
    "    temp_sampled_points = os.path.join(workspace, f\"sampled_points_{timestamp}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Converting parcels to points...\")\n",
    "        arcpy.FeatureToPoint_management(\n",
    "            in_features=parcel_polygons,\n",
    "            out_feature_class=temp_points,\n",
    "            point_location=\"INSIDE\"\n",
    "        )\n",
    "        \n",
    "        print(\"Reprojecting land use layer...\")\n",
    "        arcpy.FeatureClassToFeatureClass_conversion(\n",
    "            in_features=landuse_layer,\n",
    "            out_path=workspace,\n",
    "            out_name=f\"landuse_projected_{timestamp}\"\n",
    "        )\n",
    "        \n",
    "        print(\"Sampling land use at points...\")\n",
    "        arcpy.SpatialJoin_analysis(\n",
    "            target_features=temp_points,\n",
    "            join_features=temp_landuse,\n",
    "            out_feature_class=temp_sampled_points,\n",
    "            join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "            join_type=\"KEEP_ALL\",\n",
    "            match_option=\"INTERSECT\"\n",
    "        )\n",
    "        \n",
    "        print(\"Copying parcels to output location...\")\n",
    "        arcpy.CopyFeatures_management(parcel_polygons, output_fc)\n",
    "        \n",
    "        # Add LU field if it doesn't exist\n",
    "        if \"LU\" not in [f.name for f in arcpy.ListFields(output_fc)]:\n",
    "            arcpy.AddField_management(output_fc, \"LU\", \"TEXT\", field_length=50)\n",
    "        \n",
    "        print(\"Creating land use lookup dictionary...\")\n",
    "        landuse_dict = {}\n",
    "        with arcpy.da.SearchCursor(temp_sampled_points, [\"PID\", \"LU\"]) as cursor:\n",
    "            for pid, lu in cursor:\n",
    "                landuse_dict[pid] = lu\n",
    "        \n",
    "        print(\"Updating parcels with land use data...\")\n",
    "        with arcpy.da.UpdateCursor(output_fc, [\"PID\", \"LU\"]) as cursor:\n",
    "            for row in cursor:\n",
    "                pid = row[0]\n",
    "                if pid in landuse_dict:\n",
    "                    row[1] = landuse_dict[pid]\n",
    "                    cursor.updateRow(row)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        raise\n",
    "        \n",
    "    finally:\n",
    "        print(\"Cleaning up temporary data...\")\n",
    "        # Clean up temporary feature classes\n",
    "        for temp_fc in [temp_points, temp_landuse, temp_sampled_points]:\n",
    "            if arcpy.Exists(temp_fc):\n",
    "                arcpy.Delete_management(temp_fc)\n",
    "    \n",
    "    print(f\"Process completed successfully. Output saved to: {output_fc}\")\n",
    "    parcel_count = int(arcpy.GetCount_management(output_fc)[0])\n",
    "    print(f\"Total parcels processed: {parcel_count}\")\n",
    "\n",
    "def classify_miami(row, field_index):\n",
    "    residential_types = {\"0\", \"10\", \"11\", \"12\", \"13\", \"20\", \"30\", \"35\", \"50\", \"61\", \"435\"} \n",
    "    none_types = {\"65\", \"69\", \"160\", \"170\", \"180\", \"800\", \"801\", \"802\", \"803\", \"804\", \"805\"}\n",
    "    return 1 if row[field_index] in residential_types else None if row[field_index] in none_types else 0\n",
    "\n",
    "def get_classifier_and_field(city, fields):\n",
    "    \"\"\"Returns the appropriate classifier function and field index based on city.\"\"\"\n",
    "    city = city.lower()\n",
    "    if city == \"sacramento\":\n",
    "        return classify_sacramento, fields.index(\"LU_GENERAL\")\n",
    "    elif city == \"miami\":\n",
    "        return classify_miami, fields.index(\"LU\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported city: {city}\")\n",
    "\n",
    "def process_shapefile(input_shapefile, output_location, city):\n",
    "    \"\"\"\n",
    "    Process a shapefile by copying it and adding residential classification.\n",
    "    \n",
    "    Parameters:\n",
    "        input_shapefile (str): Path to input shapefile\n",
    "        output_location (str): Directory for output\n",
    "        city (str): City name for classification rules\n",
    "    \"\"\"\n",
    "    # Create the output paths\n",
    "    output_name = f\"{city}_residential_classified\"\n",
    "    output_path = os.path.join(output_location, output_name)\n",
    "    \n",
    "    # Copy the input feature class\n",
    "    arcpy.CopyFeatures_management(input_shapefile, output_path)\n",
    "    \n",
    "    # Add the new field\n",
    "    arcpy.AddField_management(output_path, \"res_or_not\", \"SHORT\")\n",
    "    \n",
    "    # Get the total count for progress bar\n",
    "    total_count = int(arcpy.GetCount_management(output_path)[0])\n",
    "    \n",
    "    # Process the data\n",
    "    with arcpy.da.UpdateCursor(output_path, [\"*\"]) as cursor:\n",
    "        # Get classifier function and field index once, outside the loop\n",
    "        classifier_func, field_index = get_classifier_and_field(city, cursor.fields)\n",
    "        \n",
    "        # Create progress bar\n",
    "        with tqdm(total=total_count, desc=f\"Processing {city}\") as pbar:\n",
    "            for row in cursor:\n",
    "                # Classify directly using row data and field index\n",
    "                res_value = classifier_func(row, field_index)\n",
    "                row[-1] = res_value\n",
    "                cursor.updateRow(row)\n",
    "                pbar.update(1)\n",
    "\n",
    "def update_shapefile(input_shapefile, output_location, city):\n",
    "    \"\"\"\n",
    "    Update an existing classified shapefile.\n",
    "    \n",
    "    Parameters:\n",
    "        input_shapefile (str): Path to input shapefile\n",
    "        output_location (str): Directory containing the file\n",
    "        city (str): City name for classification rules\n",
    "    \"\"\"\n",
    "    output_name = f\"{city}_residential_classified\"\n",
    "    output_path = os.path.join(output_location, output_name)\n",
    "    \n",
    "    # Get the total count for progress bar\n",
    "    total_count = int(arcpy.GetCount_management(output_path)[0])\n",
    "    \n",
    "    with arcpy.da.UpdateCursor(output_path, [\"*\"]) as cursor:\n",
    "        # Get classifier function and field index once, outside the loop\n",
    "        classifier_func, field_index = get_classifier_and_field(city, cursor.fields)\n",
    "        \n",
    "        # Create progress bar\n",
    "        with tqdm(total=total_count, desc=f\"Updating {city}\") as pbar:\n",
    "            for row in cursor:\n",
    "                # Classify directly using row data and field index\n",
    "                res_value = classifier_func(row, field_index)\n",
    "                row[-1] = res_value\n",
    "                cursor.updateRow(row)\n",
    "                pbar.update(1)\n",
    "\n",
    "def join_classifications(city_data, state_data, city_name, output_workspace):\n",
    "    \"\"\"Perform spatial join and calculate accuracy metrics.\"\"\"\n",
    "    print(f\"\\nProcessing {city_name}...\")\n",
    "    \n",
    "    # Define output file for spatial join\n",
    "    joined_fc = os.path.join(output_workspace, f\"{city_name}_validation\")\n",
    "\n",
    "    # Perform spatial join using LARGEST_OVERLAP\n",
    "    print(\"Performing spatial join...\")\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=city_data,\n",
    "        join_features=state_data,\n",
    "        out_feature_class=joined_fc,\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        join_type=\"KEEP_COMMON\",\n",
    "        match_option=\"LARGEST_OVERLAP\"\n",
    "    )\n",
    "    print(\"Joined!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify local parcel datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your output workspace\n",
    "output_workspace = os.path.join(results_path, \"validation/input_cities.gdb\")  \n",
    "\n",
    "# Need to add land use to Miami parcels\n",
    "create_miami_parcels_w_lu(os.path.join(data_path, \"city_buildings/Miami_FL/Parcel.shp\"), os.path.join(data_path, \"city_buildings/Miami_FL/Land_Use.shp\"), os.path.join(\"city_buildings/Miami_FL/parcels_with_landuse.gdb/parcels_with_landuse\"),os.path.join(data_path, \"city_buildings/Miami_FL\"))\n",
    "\n",
    "# Separate classification function for Mecklenburg county\n",
    "classify_meck(meck, os.path.join(output_workspace, \"meck_residential_classified\"))\n",
    "\n",
    "# Classify Sacramento and Miami\n",
    "cities = {\n",
    "    \"sacramento\": sacramento,\n",
    "    \"miami\": miami\n",
    "}\n",
    "\n",
    "for city, shapefile in cities.items():\n",
    "    print(f\"Processing {city}...\")\n",
    "    # process_shapefile(shapefile, output_workspace, city)\n",
    "    \n",
    "    process_shapefile(shapefile, output_workspace, city)\n",
    "    print(f\"Created new feature class for {city}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for creating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update city paths with updated classified parcel data\n",
    "output_workspace = os.path.join(results_path, \"validation/input_cities.gdb\")\n",
    "\n",
    "meck = os.path.join(output_workspace, \"meck_residential_classified\")\n",
    "sacramento = os.path.join(output_workspace, \"sacramento_residential_classified\")\n",
    "miami = os.path.join(output_workspace, \"miami_residential_classified\")\n",
    "\n",
    "# Paths to state building footprints\n",
    "state_footprints = {\n",
    "    \"NC\": os.path.join(data_path, \"overture/overture_classified.gdb/NC_buildings_class\"),\n",
    "    \"FL\": os.path.join(data_path, \"overture/overture_classified.gdb/FL_buildings_class\"),\n",
    "    \"CA\": os.path.join(data_path, \"overture/overture_classified.gdb/CA_buildings_class\")\n",
    "}\n",
    "\n",
    "# Define city-state mapping\n",
    "city_state_mapping = {\n",
    "    \"meck\": \"NC\",\n",
    "    \"sacramento\": \"CA\",\n",
    "    \"miami\": \"FL\"\n",
    "}\n",
    "\n",
    "city_to_city_mapping = {\n",
    "    \"meck\": meck,\n",
    "    \"sacramento\": sacramento,\n",
    "    \"miami\": miami\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output workspace for results\n",
    "output_workspace = os.path.join(results_path, \"validation/sj_cities.gdb\")\n",
    "\n",
    "# census blocks layer\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(results_path, \"census/blocks.gdb/blocks_floodpop\"), \"blocks_w_buildings\")\n",
    "\n",
    "# Process each city\n",
    "results = {}\n",
    "for city in [\"meck\", \"miami\", \"sacramento\"]:\n",
    "    state = city_state_mapping[city]\n",
    "    state_data = state_footprints[state]\n",
    "    state_block_data = state_footprints[state]\n",
    "    city_data = city_to_city_mapping[city]\n",
    "\n",
    "    # Perform spatial join \n",
    "    join_classifications(city_data, state_data, city, output_workspace)\n",
    "\n",
    "    # Select and export buildings that intersect with the city data\n",
    "    print(\"- Selecting buildings that intersect parcel data\")\n",
    "    arcpy.management.MakeFeatureLayer(state_data, \"state_layer\")\n",
    "    \n",
    "    arcpy.management.SelectLayerByLocation(\n",
    "        in_layer=\"state_layer\",\n",
    "        overlap_type=\"INTERSECT\",\n",
    "        select_features=city_data,\n",
    "        search_distance=None,\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        invert_spatial_relationship=\"NOT_INVERT\"\n",
    "    )\n",
    "\n",
    "    city_fc_path = os.path.join(results_path, f\"validation/buildings_cities.gdb/{city}_buildings\")\n",
    "    arcpy.conversion.ExportFeatures(\n",
    "        in_features=\"state_layer\",\n",
    "        out_features=city_fc_path,\n",
    "        where_clause=\"\",\n",
    "        use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "        sort_field=None\n",
    "    )\n",
    "\n",
    "    print(\"- Creating buildings layer with land use\")\n",
    "    city_val_path = os.path.join(results_path, f\"validation/sj_cities.gdb/{city}_validation\")\n",
    "    building_w_lu_path = os.path.join(results_path, f\"validation/buildings_cities.gdb/{city}_buildings_w_lu\")\n",
    "    \n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=city_fc_path,\n",
    "        join_features=city_val_path,\n",
    "        out_feature_class=building_w_lu_path,\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        join_type=\"KEEP_ALL\",\n",
    "        match_option=\"HAVE_THEIR_CENTER_IN\",\n",
    "        search_radius=None,\n",
    "        distance_field_name=\"\",\n",
    "        match_fields=None\n",
    "    )\n",
    "\n",
    "    city_val_blocks_path = os.path.join(results_path, f\"validation/validation_blocks.gdb/{city}_blocks\")\n",
    "    \n",
    "    print(\"- Creating census blocks for the city\")\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=\"blocks_w_buildings\",\n",
    "        join_features=building_w_lu_path,\n",
    "        out_feature_class=city_val_blocks_path,\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        join_type=\"KEEP_COMMON\",\n",
    "        match_option=\"INTERSECT\",\n",
    "        search_radius=None,\n",
    "        distance_field_name=\"\",\n",
    "        match_fields=None\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
