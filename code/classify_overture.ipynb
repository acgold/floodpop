{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classified Overture building footprints\n",
    "3/14/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "\n",
    "data_path = \"your_path\"\n",
    "scratch_gdb = \"your_scratch_path\"\n",
    "results_path = \"your_results_path\"\n",
    "\n",
    "arcpy.env.workspace = data_path\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = None\n",
    "arcpy.env.parallelProcessingFactor = \"100%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nsi_gdb = os.path.join(data_path, \"NSI/nsi_2022.gdb\")\n",
    "input_mbd_gdb = os.path.join(data_path, \"microsoft_buildings/microsoft_buildings.gdb\")\n",
    "input_usa_struct_gdb = os.path.join(data_path, \"USA_structures/usa_structures.gdb\")\n",
    "input_overture_gdb = os.path.join(data_path, \"overture/overture_2024_11_13.gdb\")\n",
    "\n",
    "# Dictionary mapping Census state FIPS codes to state abbreviations\n",
    "fips_to_abbreviation = {\n",
    "    '01': 'AL',  # Alabama\n",
    "    # '02': 'AK',  # Alaska\n",
    "    '04': 'AZ',  # Arizona: No state layer available\n",
    "    '05': 'AR',  # Arkansas\n",
    "    '06': 'CA',  # California\n",
    "    '08': 'CO',  # Colorado: No state layer available\n",
    "    '09': 'CT',  # Connecticut\n",
    "    '10': 'DE',  # Delaware\n",
    "    '11': 'DC',  # District of Columbia\n",
    "    '12': 'FL',  # Florida: No state layer available\n",
    "    '13': 'GA',  # Georgia\n",
    "    # '15': 'HI',  # Hawaii\n",
    "    '16': 'ID',  # Idaho\n",
    "    '17': 'IL',  # Illinois: No state layer available\n",
    "    '18': 'IN',  # Indiana\n",
    "    '19': 'IA',  # Iowa\n",
    "    '20': 'KS',  # Kansas\n",
    "    '21': 'KY',  # Kentucky\n",
    "    '22': 'LA',  # Louisiana\n",
    "    '23': 'ME',  # Maine\n",
    "    '24': 'MD',  # Maryland\n",
    "    '25': 'MA',  # Massachusetts\n",
    "    '26': 'MI',  # Michigan\n",
    "    '27': 'MN',  # Minnesota\n",
    "    '28': 'MS',  # Mississippi: No state layer available\n",
    "    '29': 'MO',  # Missouri\n",
    "    '30': 'MT',  # Montana\n",
    "    '31': 'NE',  # Nebraska\n",
    "    '32': 'NV',  # Nevada\n",
    "    '33': 'NH',  # New Hampshire\n",
    "    '34': 'NJ',  # New Jersey\n",
    "    '35': 'NM',  # New Mexico: No state layer available\n",
    "    '36': 'NY',  # New York\n",
    "    '37': 'NC',  # North Carolina\n",
    "    '38': 'ND',  # North Dakota\n",
    "    '39': 'OH',  # Ohio\n",
    "    '40': 'OK',  # Oklahoma\n",
    "    '41': 'OR',  # Oregon\n",
    "    '42': 'PA',  # Pennsylvania\n",
    "    '44': 'RI',  # Rhode Island\n",
    "    '45': 'SC',  # South Carolina\n",
    "    '46': 'SD',  # South Dakota\n",
    "    '47': 'TN',  # Tennessee\n",
    "    '48': 'TX',  # Texas: No state layer available\n",
    "    '49': 'UT',  # Utah\n",
    "    '50': 'VT',  # Vermont\n",
    "    '51': 'VA',  # Virginia\n",
    "    '53': 'WA',  # Washington\n",
    "    '54': 'WV',  # West Virginia\n",
    "    '55': 'WI',  # Wisconsin\n",
    "    '56': 'WY'   # Wyoming\n",
    "}\n",
    "\n",
    "stfips = list(fips_to_abbreviation.values())[0:50]\n",
    "stfips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run classification workflow for contiguous US states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in stfips:\n",
    "    print(f\"Working on {st}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # load input data\n",
    "    nsi_layer = arcpy.management.MakeFeatureLayer(os.path.join(input_nsi_gdb, f\"{st}_nsi_2022\"), \"nsi_layer\")\n",
    "    mbd_layer = arcpy.management.MakeFeatureLayer(os.path.join(input_mbd_gdb, f\"{st}_mbd\"), \"mbd_layer\")\n",
    "    usa_struct_layer = arcpy.management.MakeFeatureLayer(os.path.join(input_usa_struct_gdb, f\"{st}_Structures\"), \"usa_struct_layer\")\n",
    "    overture_layer = arcpy.management.MakeFeatureLayer(os.path.join(input_overture_gdb, f\"{st}_buildings\"), \"overture_layer\")\n",
    "        \n",
    "\n",
    "    print(\"Selecting NSI that does not overlap Overture buildings\")\n",
    "    arcpy.management.SelectLayerByLocation(\n",
    "        in_layer=nsi_layer,\n",
    "        overlap_type=\"INTERSECT\",\n",
    "        select_features=overture_layer,\n",
    "        search_distance=None,\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        invert_spatial_relationship=\"INVERT\"\n",
    "    )\n",
    "\n",
    "    nsi_selected_layer = os.path.join(scratch_gdb, \"nsi_no_overture_intersect\")\n",
    "    \n",
    "    arcpy.management.CopyFeatures(nsi_layer, nsi_selected_layer)\n",
    "\n",
    "    # Create dynamic field mappings for the spatial joins later\n",
    "    mbd_fieldmappings_string = f'release \"release\" true true false 8 Double 0 0,Range,#,{input_mbd_gdb}/{st}_mbd,release,-1,-1;capture_dates_range \"capture_dates_range\" true true false 2000000000 Text 0 0,Join,\",\",{input_mbd_gdb}/{st}_mbd,capture_dates_range,0,1999999999;Shape_Length \"Shape_Length\" false true true 8 Double 0 0,First,#,{st}_mbd,Shape_Length,-1,-1,{input_mbd_gdb}/{st}_mbd,Shape_Length,-1,-1;Shape_Area \"Shape_Area\" false true true 8 Double 0 0,First,#,{input_mbd_gdb}/{st}_mbd,Shape_Area,-1,-1;fd_id \"fd_id\" true true false 2000 Text 0 0,Join,\",\",{st}_nsi_2022,fd_id,-1,-1;bid \"bid\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,bid,0,2147483646;cbfips \"cbfips\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,cbfips,0,2147483646;st_damcat \"st_damcat\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,st_damcat,0,2147483646;occtype \"occtype\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,occtype,0,2147483646;num_story \"num_story\" true true false 8 Double 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,num_story,-1,-1;sqft \"sqft\" true true false 20000 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,sqft,-1,-1;ftprntid \"ftprntid\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,ftprntid,0,2147483646;ftprntsrc \"ftprntsrc\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,ftprntsrc,0,2147483646;source \"source\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,source,0,2147483646'\n",
    "    mbd_fieldmappings = arcpy.FieldMappings()\n",
    "    mbd_fieldmappings.loadFromString(mbd_fieldmappings_string)\n",
    "    \n",
    "    usa_fieldmappings_string = f'usa_id \"usa_id\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,BUILD_ID,-1,-1;usa_height \"usa_height\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,HEIGHT,-1,-1;usa_image_date \"usa_image_date\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,IMAGE_DATE,-1,-1;usa_occ_cls \"usa_occ_cls\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,OCC_CLS,0,19;usa_prim_occ \"usa_prim_occ\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,PRIM_OCC,0,34;usa_prop_addr \"usa_prop_addr\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,PROP_ADDR,0,79;usa_prop_city \"usa_prop_city\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,PROP_CITY,0,49;usa_prop_st \"usa_prop_st\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,PROP_ST,0,49;usa_prop_zip \"usa_prop_zip\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,PROP_ZIP,0,49;usa_sec_occ \"usa_sec_occ\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,SEC_OCC,0,12;usa_source \"usa_source\" true true false 255 Text 0 0,Join,\",\",{input_usa_struct_gdb}/{st}_Structures,SOURCE,0,49;fd_id \"fd_id\" true true false 2000 Text 0 0,Join,\",\",{st}_nsi_2022,fd_id,-1,-1;bid \"bid\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,bid,0,2147483646;cbfips \"cbfips\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,cbfips,0,2147483646;st_damcat \"st_damcat\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,st_damcat,0,2147483646;occtype \"occtype\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,occtype,0,2147483646;num_story \"num_story\" true true false 8 Double 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,num_story,-1,-1;sqft \"sqft\" true true false 20000 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,sqft,-1,-1;ftprntid \"ftprntid\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,ftprntid,0,2147483646;ftprntsrc \"ftprntsrc\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,ftprntsrc,0,2147483646;source \"source\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,source,0,2147483646'\n",
    "    usa_fieldmappings = arcpy.FieldMappings()\n",
    "    usa_fieldmappings.loadFromString(usa_fieldmappings_string)\n",
    "    \n",
    "    overture_fieldmappings_string = f'overture_id \"overture_id\" true true false 255 Text 0 0,Join,\",\",{input_overture_gdb}/{st}_buildings,id,0,31;overture_source \"overture_source\" true true false 255 Text 0 0,Join,\",\",{input_overture_gdb}/{st}_buildings,source,0,99;overture_class \"overture_class\" true true false 255 Text 0 0,Join,\",\",{input_overture_gdb}/{st}_buildings,class,0,99;overture_height \"overture_height\" true true false 255 Text 0 0,Join,\",\",{input_overture_gdb}/{st}_buildings,height,-1,-1;overture_num_floors \"overture_num_floors\" true true false 255 Long 0 0,First,#,{input_overture_gdb}/{st}_buildings,num_floors,-1,-1;overture_subtype \"overture_subtype\" true true false 255 Text 0 0,Join,\",\",{input_overture_gdb}/{st}_buildings,subtype,0,99;overture_update_time \"overture_update_time\" true true false 255 Text 0 0,Join,\",\",{input_overture_gdb}/{st}_buildings,update_time,0,99;fd_id \"fd_id\" true true false 2000 Text 0 0,Join,\",\",{st}_nsi_2022,fd_id,-1,-1;bid \"bid\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,bid,0,2147483646;cbfips \"cbfips\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,cbfips,0,2147483646;st_damcat \"st_damcat\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,st_damcat,0,2147483646;occtype \"occtype\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,occtype,0,2147483646;num_story \"num_story\" true true false 8 Double 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,num_story,-1,-1;sqft \"sqft\" true true false 20000 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,sqft,-1,-1;ftprntid \"ftprntid\" true true false 2147483647 Text 0 0,First,#,{input_nsi_gdb}/{st}_nsi_2022,ftprntid,0,2147483646;ftprntsrc \"ftprntsrc\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,ftprntsrc,0,2147483646;source \"source\" true true false 2147483647 Text 0 0,Join,\",\",{input_nsi_gdb}/{st}_nsi_2022,source,0,2147483646'\n",
    "    overture_fieldmappings = arcpy.FieldMappings()\n",
    "    overture_fieldmappings.loadFromString(overture_fieldmappings_string)\n",
    "\n",
    "    # Select 'Bing' footprint sources, and find the MBD footprints that\n",
    "    print(\"Selecting NSI points that align with Microsoft Building footprints\")\n",
    "    arcpy.management.SelectLayerByAttribute(\n",
    "        in_layer_or_view=nsi_selected_layer,\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        where_clause=\"ftprntsrc = 'Bing' And source <> 'X'\",\n",
    "        invert_where_clause=None\n",
    "    )\n",
    "    \n",
    "    arcpy.management.SelectLayerByLocation(\n",
    "        in_layer=mbd_layer,\n",
    "        overlap_type=\"HAVE_THEIR_CENTER_IN\",\n",
    "        select_features=nsi_selected_layer,\n",
    "        search_distance=\"0.5 Meters\",\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        invert_spatial_relationship=\"NOT_INVERT\"\n",
    "    )\n",
    "\n",
    "    arcpy.management.SelectLayerByLocation(\n",
    "        in_layer=mbd_layer,\n",
    "        overlap_type=\"INTERSECT\",\n",
    "        select_features=overture_layer,\n",
    "        search_distance=None,\n",
    "        selection_type=\"REMOVE_FROM_SELECTION\",\n",
    "        invert_spatial_relationship=\"NOT_INVERT\"\n",
    "    )\n",
    "\n",
    "    arcpy.management.MakeFeatureLayer(mbd_layer, \"nsi_mbd_ftprnt\", where_clause=\"\")  \n",
    "    arcpy.conversion.ExportFeatures(\"nsi_mbd_ftprnt\", os.path.join(scratch_gdb, \"nsi_mbd_ftprnt\"))\n",
    "\n",
    "    arcpy.management.SelectLayerByAttribute(\n",
    "        in_layer_or_view=nsi_selected_layer,\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        where_clause=\"ftprntsrc IN ('NGA', 'ORNL') And source <> 'X'\", #\n",
    "        invert_where_clause=None\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(\"Selecting NSI points that align with USA Structures\")\n",
    "    arcpy.management.SelectLayerByLocation(\n",
    "        in_layer=usa_struct_layer,\n",
    "        overlap_type=\"HAVE_THEIR_CENTER_IN\",\n",
    "        select_features=nsi_selected_layer,\n",
    "        search_distance=\"0.5 Meters\",\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        invert_spatial_relationship=\"NOT_INVERT\"\n",
    "    )\n",
    "\n",
    "    arcpy.management.SelectLayerByLocation(\n",
    "        in_layer=usa_struct_layer,\n",
    "        overlap_type=\"INTERSECT\",\n",
    "        select_features=overture_layer,\n",
    "        search_distance=None,\n",
    "        selection_type=\"REMOVE_FROM_SELECTION\",\n",
    "        invert_spatial_relationship=\"NOT_INVERT\"\n",
    "    )\n",
    "\n",
    "    arcpy.management.MakeFeatureLayer(usa_struct_layer, \"nsi_usa_struc_ftprnt\", where_clause=\"\")  \n",
    "    arcpy.conversion.ExportFeatures(\"nsi_usa_struc_ftprnt\", os.path.join(scratch_gdb, \"nsi_usa_struc_ftprnt\"))\n",
    "\n",
    "    print(\"Merging all buildings\")\n",
    "    arcpy.management.Merge(\n",
    "        inputs=\"overture_layer;nsi_mbd_ftprnt;nsi_usa_struc_ftprnt\",\n",
    "        output=os.path.join(scratch_gdb, \"overture_layer_Merge\"),\n",
    "        field_mappings='id \"id\" true true false 32 Text 0 0,First,#,overture_layer,id,0,31;height \"height\" true true false 4 Float 0 0,First,#,overture_layer,height,-1,-1;source \"source\" true true false 2147483647 Text 0 0,First,#,overture_layer,source,0,99;update_time \"update_time\" true true false 100 Text 0 0,First,#,overture_layer,update_time,0,99;subtype \"subtype\" true true false 100 Text 0 0,First,#,overture_layer,subtype,0,99;class \"class\" true true false 100 Text 0 0,First,#,overture_layer,class,0,99;level \"level\" true true false 4 Long 0 0,First,#,overture_layer,level,-1,-1;num_floors \"num_floors\" true true false 4 Long 0 0,First,#,overture_layer,num_floors,-1,-1;release \"release\" true true false 8 Double 0 0,First,#,nsi_mbd_ftprnt,release,-1,-1;capture_dates_range \"capture_dates_range\" true true false 2000000000 Text 0 0,First,#,nsi_mbd_ftprnt,capture_dates_range,0,1999999999;PROD_DATE \"PROD_DATE\" true true false 8 Date 0 0,First,#,nsi_usa_struc_ftprnt,PROD_DATE,-1,-1;IMAGE_DATE \"IMAGE_DATE\" true true false 8 Date 0 0,First,#,nsi_usa_struc_ftprnt,IMAGE_DATE,-1,-1;Shape_Length \"Shape_Length\" false true true 8 Double 0 0,First,#,overture_layer,Shape_Length,-1,-1,nsi_mbd_ftprnt,Shape_Length,-1,-1,nsi_usa_struc_ftprnt,Shape_Length,-1,-1;Shape_Area \"Shape_Area\" false true true 8 Double 0 0,First,#,overture_layer,Shape_Area,-1,-1,nsi_mbd_ftprnt,Shape_Area,-1,-1,nsi_usa_struc_ftprnt,Shape_Area,-1,-1',\n",
    "        add_source=\"NO_SOURCE_INFO\",\n",
    "        field_match_mode=\"MANUAL_EDIT\"\n",
    "    )\n",
    "\n",
    "    overture_merged = arcpy.management.MakeFeatureLayer(os.path.join(scratch_gdb, \"overture_layer_Merge\"), \"overture_merged\")\n",
    "\n",
    "    arcpy.management.SelectLayerByAttribute(\n",
    "        in_layer_or_view=usa_struct_layer,\n",
    "        selection_type=\"CLEAR_SELECTION\",\n",
    "        where_clause=\"\",\n",
    "        invert_where_clause=None\n",
    "    )\n",
    "    \n",
    "    arcpy.management.SelectLayerByAttribute(\n",
    "        in_layer_or_view=nsi_layer,\n",
    "        selection_type=\"CLEAR_SELECTION\",\n",
    "        where_clause=\"\",\n",
    "        invert_where_clause=None\n",
    "    )\n",
    "\n",
    "    print(\"Joining overture and USA structures layers\")\n",
    "    arcpy.gapro.JoinFeatures(\n",
    "        target_layer=overture_merged,\n",
    "        join_layer=usa_struct_layer,\n",
    "        output=os.path.join(scratch_gdb, \"buildings_class\"),\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        spatial_relationship=\"INTERSECTS\",\n",
    "        spatial_near_distance=None,\n",
    "        temporal_relationship=\"\",\n",
    "        temporal_near_distance=None,\n",
    "        attribute_relationship=None,\n",
    "        summary_fields=\"OCC_CLS MAX;PRIM_OCC MAX;IMAGE_DATE MAX;HEIGHT MAX;UUID MAX\",\n",
    "        join_condition=\"\",\n",
    "        keep_all_target_features=\"KEEP_ALL\",\n",
    "        include_distance=None,\n",
    "        distance_unit=\"\"\n",
    "    )\n",
    "\n",
    "    print(\"Joining overture and nsi layers\")\n",
    "    arcpy.gapro.JoinFeatures(\n",
    "        target_layer=os.path.join(scratch_gdb, \"buildings_class\"),\n",
    "        join_layer=nsi_layer,\n",
    "        output=os.path.join(scratch_gdb, \"buildings_class_nsi\"),\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        spatial_relationship=\"NEAR\",\n",
    "        spatial_near_distance=\"10 Meters\",\n",
    "        temporal_relationship=\"\",\n",
    "        temporal_near_distance=None,\n",
    "        attribute_relationship=None,\n",
    "        summary_fields=\"st_damcat MAX;bid MAX\",\n",
    "        join_condition=None, \n",
    "        keep_all_target_features=\"KEEP_ALL\",\n",
    "        include_distance=None,\n",
    "        distance_unit=\"\"\n",
    "    )\n",
    "\n",
    "    overture_classified = arcpy.management.MakeFeatureLayer(os.path.join(scratch_gdb, \"buildings_class_nsi\"), \"overture_classified\")\n",
    "    \n",
    "    # Create final layer with res_or_not\n",
    "    print(\"Calculating Residential or Not\")\n",
    "    arcpy.gapro.CalculateField(\n",
    "        input_layer=overture_classified,\n",
    "        output=os.path.join(scratch_gdb, \"buildings_class_w_stacks\"),\n",
    "        field_to_calculate=\"NEW_FIELD\",\n",
    "        field_name=\"res_or_not\",\n",
    "        existing_field=None,\n",
    "        field_type=\"INTEGER\",\n",
    "        expression='IIf($feature.subtype != null, IIf($feature.subtype == \"residential\", IIf($feature.class == \"garage\" || $feature.class == \"garages\" || $feature.class == \"parking\", 0, IIf($feature.MAX_OCC_CLS != null || $feature.MAX_st_damcat != null, 1, IIf($feature.update_time < \"2021-01-01\", 1, -1))),0), IIf($feature.MAX_OCC_CLS != null && $feature.MAX_OCC_CLS != \"Unclassified\", IIf($feature.MAX_OCC_CLS == \"Residential\" && $feature.MAX_PRIM_OCC != \"Temporary Lodging\", 1, 0), IIf($feature.MAX_st_damcat != null, IIf($feature.MAX_st_damcat == \"RES\", 1, 0), -1)))',\n",
    "        track_aware=None,\n",
    "        track_fields=None,\n",
    "        time_boundary_split=None,\n",
    "        time_boundary_reference=None\n",
    "    )\n",
    "\n",
    "    overture_classified = arcpy.management.MakeFeatureLayer(os.path.join(scratch_gdb, \"buildings_class_w_stacks\"), \"overture_classified\")\n",
    "    \n",
    "    print(\"Unioning buildings\")\n",
    "    with arcpy.EnvManager(parallelProcessingFactor=\"100%\"):\n",
    "        arcpy.analysis.Union(\n",
    "            in_features=overture_classified,\n",
    "            out_feature_class=os.path.join(scratch_gdb, \"buildings_class_w_stacks_union\"),\n",
    "            join_attributes=\"ALL\",\n",
    "            cluster_tolerance=None,\n",
    "            gaps=\"GAPS\"\n",
    "        )\n",
    "\n",
    "    overture_classified_union = arcpy.management.MakeFeatureLayer(os.path.join(scratch_gdb, \"buildings_class_w_stacks_union\"), \"overture_classified\")\n",
    "    \n",
    "    print(\"Finding identical geometries in buildings - these are overlaps or duplicates\")\n",
    "    arcpy.management.FindIdentical(\n",
    "        in_dataset=overture_classified_union,\n",
    "        out_dataset=os.path.join(scratch_gdb, \"overture_class_FindIdentical\"),\n",
    "        fields=\"SHAPE\",\n",
    "        xy_tolerance=None,\n",
    "        z_tolerance=0,\n",
    "        output_record_option=\"ONLY_DUPLICATES\"\n",
    "    )\n",
    "    \n",
    "    # Input layer and identical table\n",
    "    input_layer =overture_classified_union  \n",
    "    identical_table = os.path.join(scratch_gdb, \"overture_class_FindIdentical\")  \n",
    "    \n",
    "    # Create a dictionary to group features by FEAT_SEQ\n",
    "    identical_dict = {}\n",
    "    with arcpy.da.SearchCursor(identical_table, [\"FEAT_SEQ\", \"IN_FID\"]) as cursor:\n",
    "        for feat_seq, in_fid in cursor:\n",
    "            if feat_seq not in identical_dict:\n",
    "                identical_dict[feat_seq] = []\n",
    "            identical_dict[feat_seq].append(in_fid)\n",
    "    \n",
    "    # List to store OBJECTID_1 values of features to delete\n",
    "    features_to_delete = []\n",
    "    \n",
    "    print(\"Deleting identicals, prioritizing residential and more recent polygons\")\n",
    "    # Process each FEAT_SEQ group\n",
    "    with arcpy.da.SearchCursor(input_layer, [\"OBJECTID_1\", \"res_or_not\", \"update_time\"]) as search_cursor:\n",
    "        features_data = {row[0]: row for row in search_cursor}  # Store all rows in a dictionary for quick lookup\n",
    "    \n",
    "    for feat_seq, fids in identical_dict.items():\n",
    "        # Collect all features in the current FEAT_SEQ group\n",
    "        features = [features_data[fid] for fid in fids if fid in features_data]\n",
    "    \n",
    "        # Sort features by prioritization rules\n",
    "        # 1. Prioritize by res_or_not (descending)\n",
    "        # 2. Then by most recent update_time\n",
    "        # 3. If equal, pick the first in sorted order\n",
    "        features.sort(key=lambda x: (-x[1], x[2] or datetime.min))\n",
    "    \n",
    "        # Mark features to delete except the highest-priority one\n",
    "        features_to_delete.extend([row[0] for row in features[1:]])\n",
    "    \n",
    "    # Delete marked features in bulk using a SQL query\n",
    "    if features_to_delete:\n",
    "        # Convert list of IDs to a comma-separated string\n",
    "        delete_ids = \", \".join(map(str, features_to_delete))\n",
    "        \n",
    "        # Build a SQL query to select features for deletion\n",
    "        sql_query = f\"OBJECTID_1 IN ({delete_ids})\"\n",
    "        \n",
    "        # Use MakeFeatureLayer and DeleteFeatures for bulk deletion\n",
    "        arcpy.MakeFeatureLayer_management(input_layer, \"temp_layer\", sql_query)\n",
    "        arcpy.DeleteFeatures_management(\"temp_layer\")\n",
    "    \n",
    "        print(f\"Deleted {len(features_to_delete)} duplicate features.\")\n",
    "\n",
    "    print(\"Repairing geometries\")\n",
    "    arcpy.management.RepairGeometry(\n",
    "        in_features=overture_classified_union,\n",
    "        delete_null=\"DELETE_NULL\",\n",
    "        validation_method=\"OGC\"\n",
    "    )\n",
    "    \n",
    "    buildings_layer = overture_classified_union   # Full dataset of buildings\n",
    "    floodplain_layer = f\"{data_path}/floodplain/nfhl/sfha_dec_12_2024.gdb/{st}_sfha\"  \n",
    "    est_floodplain_layer = os.path.join(data_path, \"estimated_floodplain/estimated_floodplain_CONUS.gdb/estimated_floodplain_CONUS\")\n",
    "    \n",
    "    sfha_output = os.path.join(scratch_gdb, \"sfha_scratch\")  # Temporary output\n",
    "    est_sfha_output = os.path.join(scratch_gdb, \"est_sfha_scratch\") # Temporary output\n",
    "    \n",
    "    census_blocks = os.path.join(data_path, \"census/blocks/tlgdb_2024_a_us_block.gdb/Block20_proj\")\n",
    "    state_cb = os.path.join(data_path,\"census/blocks/blocks_by_state.gdb\",st+\"_blocks\")\n",
    "    \n",
    "    state_bounds = os.path.join(scratch_gdb, \"state_bounds\")\n",
    "    all_state_bounds = os.path.join(data_path, \"census/state_boundaries/tl_2024_us_state_proj.shp\")\n",
    "    \n",
    "    print(\"Selecting the state\")\n",
    "    arcpy.analysis.Select(all_state_bounds, state_bounds, f\"STUSPS = '{st}'\")\n",
    "    \n",
    "    print(\"Clipping census blocks to the state bounds\")\n",
    "    arcpy.analysis.PairwiseClip(\n",
    "        census_blocks, \n",
    "        state_bounds,\n",
    "        state_cb\n",
    "    )\n",
    "    \n",
    "    print(\"Clipping the buildings with the SFHA\")\n",
    "    arcpy.gapro.ClipLayer(buildings_layer, floodplain_layer, sfha_output)\n",
    "    \n",
    "    #  Extract OBJECTID_1 values from the clip result for SFHA\n",
    "    print(\"Finding objectid values of clip\")\n",
    "    objectid_list = []\n",
    "    with arcpy.da.SearchCursor(sfha_output, [\"OBJECTID_1\"]) as cursor:\n",
    "        objectid_list = [row[0] for row in cursor]\n",
    "    \n",
    "    # Step 3: Update the \"within_sfha\" field in the overall buildings dataset\n",
    "    if objectid_list:\n",
    "        # Ensure the field \"within_sfha\" exists; add it if not\n",
    "        field_names = [f.name for f in arcpy.ListFields(buildings_layer)]\n",
    "        if \"within_sfha\" not in field_names:\n",
    "            print(\"Adding field 'within_sfha'\")\n",
    "            arcpy.AddField_management(buildings_layer, \"within_sfha\", \"SHORT\")\n",
    "    \n",
    "        # Build a SQL query to select buildings within the intersection\n",
    "        objectid_query = \", \".join(map(str, objectid_list))\n",
    "        sql_query = f\"OBJECTID_1 IN ({objectid_query})\"\n",
    "    \n",
    "        # Use an UpdateCursor to set the \"within_sfha\" field to 1\n",
    "        print(\"Updating buildings layers\")\n",
    "        with arcpy.da.UpdateCursor(buildings_layer, [\"OBJECTID_1\", \"within_sfha\"], sql_query) as cursor:\n",
    "            for row in cursor:\n",
    "                row[1] = 1\n",
    "                cursor.updateRow(row)\n",
    "    \n",
    "        print(f\"Updated {len(objectid_list)} buildings with 'within_sfha = 1'.\")\n",
    "    else:\n",
    "        print(\"No buildings found within the floodplain.\")\n",
    "    \n",
    "    \n",
    "    print(\"Clipping est sfha to state\")\n",
    "    state_est_sfha = os.path.join(scratch_gdb, \"state_est_sfha\")\n",
    "    arcpy.analysis.PairwiseClip(est_floodplain_layer, state_bounds, state_est_sfha)\n",
    "    \n",
    "    print(\"Clipping the buildings to state est sfha\")\n",
    "    arcpy.gapro.ClipLayer(buildings_layer, state_est_sfha, est_sfha_output)\n",
    "    \n",
    "    #  Extract OBJECTID_1 values from the clip result for SFHA\n",
    "    print(\"Finding objectid values of clip\")\n",
    "    objectid_list = []\n",
    "    with arcpy.da.SearchCursor(est_sfha_output, [\"OBJECTID_1\"]) as cursor:\n",
    "        objectid_list = [row[0] for row in cursor]\n",
    "    \n",
    "    # Step 3: Update the \"within_sfha\" field in the overall buildings dataset\n",
    "    if objectid_list:\n",
    "        # Ensure the field \"within_sfha\" exists; add it if not\n",
    "        field_names = [f.name for f in arcpy.ListFields(buildings_layer)]\n",
    "        if \"within_est_sfha\" not in field_names:\n",
    "            print(\"Adding field 'within_est_sfha'\")\n",
    "            arcpy.AddField_management(buildings_layer, \"within_est_sfha\", \"SHORT\")\n",
    "    \n",
    "        # Build a SQL query to select buildings within the intersection\n",
    "        objectid_query = \", \".join(map(str, objectid_list))\n",
    "        sql_query = f\"OBJECTID_1 IN ({objectid_query})\"\n",
    "    \n",
    "        # Use an UpdateCursor to set the \"within_sfha\" field to 1\n",
    "        print(\"Updating buildings layers\")\n",
    "        with arcpy.da.UpdateCursor(buildings_layer, [\"OBJECTID_1\", \"within_est_sfha\"], sql_query) as cursor:\n",
    "            for row in cursor:\n",
    "                row[1] = 1\n",
    "                cursor.updateRow(row)\n",
    "    \n",
    "        print(f\"Updated {len(objectid_list)} buildings with 'within_est_sfha = 1'.\")\n",
    "    else:\n",
    "        print(\"No buildings found within the floodplain.\")\n",
    "\n",
    "    print(\"Spatial joining census blocks with buildings\")\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=overture_classified_union,\n",
    "        join_features=state_cb,\n",
    "        out_feature_class=os.path.join(data_path, f\"overture/overture_classified.gdb/{st}_buildings_class\"),\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        join_type=\"KEEP_ALL\",\n",
    "        field_mapping=f'OBJECTID \"OBJECTID\" true true false 4 Long 0 0,First,#,buildings_class_w_stacks_union,FID_buildings_class_w_stacks,-1,-1;id \"id\" true true false 32 Text 0 0,First,#,buildings_class_w_stacks_union,id,0,31;height \"height\" true true false 4 Float 0 0,First,#,buildings_class_w_stacks_union,height,-1,-1;source \"source\" true true false 100 Text 0 0,First,#,buildings_class_w_stacks_union,source,0,99;update_time \"update_time\" true true false 100 Text 0 0,First,#,buildings_class_w_stacks_union,update_time,0,99;subtype \"subtype\" true true false 100 Text 0 0,First,#,buildings_class_w_stacks_union,subtype,0,99;class \"class\" true true false 100 Text 0 0,First,#,buildings_class_w_stacks_union,class,0,99;level \"level\" true true false 4 Long 0 0,First,#,buildings_class_w_stacks_union,level,-1,-1;num_floors \"num_floors\" true true false 4 Long 0 0,First,#,buildings_class_w_stacks_union,num_floors,-1,-1;MAX_OCC_CLS \"MAX_OCC_CLS\" true true false 10485758 Text 0 0,First,#,buildings_class_w_stacks_union,MAX_OCC_CLS,0,10485757;MAX_PRIM_OCC \"MAX_PRIM_OCC\" true true false 10485758 Text 0 0,First,#,buildings_class_w_stacks_union,MAX_PRIM_OCC,0,10485757;MAX_UUID \"MAX_UUID\" true true false 10485758 Text 0 0,First,#,buildings_class_w_stacks_union,MAX_UUID,0,10485757;MAX_IMAGE_DATE \"MAX_IMAGE_DATE\" true true false 8 Date 0 0,First,#,buildings_class_w_stacks_union,MAX_IMAGE_DATE,-1,-1;MAX_HEIGHT \"MAX_HEIGHT\" true true false 4 Float 0 0,First,#,buildings_class_w_stacks_union,MAX_HEIGHT,-1,-1;MAX_st_damcat \"MAX_st_damcat\" true true false 10485758 Text 0 0,First,#,buildings_class_w_stacks_union,MAX_st_damcat,0,10485757;MAX_bid \"MAX_bid\" true true false 10485758 Text 0 0,First,#,buildings_class_w_stacks_union,MAX_bid,0,10485757;res_or_not \"res_or_not\" true true false 4 Long 0 0,First,#,buildings_class_w_stacks_union,res_or_not,-1,-1;within_sfha \"within_sfha\" true true false 2 Short 0 0,First,#,buildings_class_w_stacks_union,within_sfha,-1,-1;within_est_sfha \"within_est_sfha\" true true false 2 Short 0 0,First,#,buildings_class_w_stacks_union,within_est_sfha,-1,-1;GEOID20 \"GEOID20\" true true false 15 Text 0 0,First,#,{state_cb},GEOID20,0,14;SHAPE_Length \"SHAPE_Length\" false true true 8 Double 0 0,First,#,buildings_class_w_stacks_union,SHAPE_Length,-1,-1;SHAPE_Area \"SHAPE_Area\" false true true 8 Double 0 0,First,#,buildings_class_w_stacks_union,SHAPE_Area,-1,-1',\n",
    "        match_option=\"HAVE_THEIR_CENTER_IN\",\n",
    "        search_radius=None,\n",
    "        distance_field_name=\"\",\n",
    "        match_fields=None\n",
    "    )\n",
    "\n",
    "    # List of fields to delete\n",
    "    fields_to_delete = [\"Join_Count\", \"TARGET_FID\"]\n",
    "    \n",
    "    # Delete extra fields\n",
    "    print(\"Deleting extra fields\")\n",
    "    arcpy.management.DeleteField(os.path.join(data_path, f\"overture/overture_classified.gdb/{st}_buildings_class\"), fields_to_delete)\n",
    "\n",
    "    arcpy.management.Delete(os.path.join(scratch_gdb, \"buildings_class\"))\n",
    "    arcpy.management.Delete(os.path.join(scratch_gdb, \"buildings_class_nsi\"))\n",
    "    arcpy.management.Delete(overture_merged)\n",
    "    arcpy.management.Delete(overture_classified_union)\n",
    "    arcpy.management.Delete(sfha_output)\n",
    "    arcpy.management.Delete(est_sfha_output)\n",
    "    arcpy.management.Delete(identical_table)\n",
    "    arcpy.management.Delete(overture_classified)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(round(elapsed_time/60, 2), \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run final operation to tag buildings if they are in a FEMA study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfhl_footprint = os.path.join(data_path, \"floodplain/nfhl/nfhl_footprints.gdb/nfhl_footprint_simple\")\n",
    "state_nfhl_footprint = os.path.join(scratch_gdb, \"state_nfhl_footprint\")\n",
    "\n",
    "for st in stfips:\n",
    "    print(f\"Working on {st}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    state_bounds = os.path.join(scratch_gdb, \"state_bounds\")\n",
    "    all_state_bounds = os.path.join(data_path, \"census/state_boundaries/tl_2024_us_state_proj.shp\")\n",
    "\n",
    "    buildings_layer = os.path.join(data_path, f\"overture/overture_classified.gdb/{st}_buildings_class\")\n",
    "    output_buildings = os.path.join(results_path, f\"building_footprints.gdb/{st}_buildings_fp\")\n",
    "    \n",
    "    print(\"Selecting the state\")\n",
    "    arcpy.analysis.Select(all_state_bounds, state_bounds, f\"STUSPS = '{st}'\")\n",
    "    \n",
    "    print(\"Clipping NFHL footprint to the state bounds\")\n",
    "    arcpy.analysis.PairwiseClip(\n",
    "        nfhl_footprint, \n",
    "        state_bounds,\n",
    "        state_nfhl_footprint\n",
    "    )\n",
    "\n",
    "    print(\"Spatial joining nfhl footprint with buildings\")\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=buildings_layer,\n",
    "        join_features=state_nfhl_footprint,\n",
    "        out_feature_class=output_buildings,\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        join_type=\"KEEP_ALL\",\n",
    "        match_option=\"HAVE_THEIR_CENTER_IN\",\n",
    "        search_radius=None,\n",
    "        distance_field_name=\"\",\n",
    "        match_fields=None\n",
    "    )\n",
    "\n",
    "    # List of fields to delete\n",
    "    fields_to_delete = [\"Join_Count\", \"TARGET_FID\", \"OBJECTID\", \"Shape_Length_1\", \"Shape_Area_1\"]\n",
    "    \n",
    "    # Delete extra fields\n",
    "    print(\"Deleting extra fields\")\n",
    "    arcpy.management.DeleteField(output_buildings, fields_to_delete)\n",
    "\n",
    "    # Get a list of fields\n",
    "    fields = [f.name for f in arcpy.ListFields(output_buildings)]\n",
    "\n",
    "    if \"OBJECTID_1\" in fields:\n",
    "        print(\"Renaming alias of 'OBJECTID_1'\")\n",
    "        arcpy.management.AlterField(output_buildings, \"OBJECTID_1\", new_field_alias = \"OBJECTID\")\n",
    "        print(\"Renaming successful.\")\n",
    "    else:\n",
    "        print(\"'OBJECTID_1' column not found.\")\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(round(elapsed_time/60, 2), \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export tabular data to Parquet files for analysis in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file geodatabase path\n",
    "gdb_path = os.path.join(results_path, \"building_footprints.gdb\")\n",
    "\n",
    "# List all feature classes in the geodatabase\n",
    "arcpy.env.workspace = gdb_path\n",
    "feature_classes = arcpy.ListFeatureClasses()\n",
    "\n",
    "output_folder = os.path.join(results_path, \"building_footprint_dfs\")\n",
    "\n",
    "# Function to read attribute table into a pandas dataframe\n",
    "def feature_class_to_dataframe(fc):\n",
    "    state_name = fc.split(\"_\")[0]\n",
    "    \n",
    "    fields = [f.name for f in arcpy.ListFields(fc) if f.type != \"Geometry\"]\n",
    "    with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "        data = [row for row in cursor]\n",
    "\n",
    "    pd.DataFrame(data, columns=fields).to_parquet(os.path.join(output_folder, state_name + \"_buildings_fp.parquet\"))\n",
    "    print(f\"Fininshed {state_name}\")\n",
    "    return \n",
    "\n",
    "# Read all feature classes into a dictionary of dataframes\n",
    "dataframes = {fc: feature_class_to_dataframe(fc) for fc in feature_classes}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
