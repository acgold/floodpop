{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download National Structure Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import urllib.request\n",
    "import json\n",
    "import io\n",
    "import zipfile\n",
    "import arcpy\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"USA Contiguous Albers Equal Area Conic USGS\")\n",
    "arcpy.env.parallelProcessingFactor = \"100%\"\n",
    "\n",
    "data_path = \"your_path_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download all structures\n",
    "# Base URL for the downloads\n",
    "base_url = \"https://nsi.sec.usace.army.mil/downloads/nsi_2022/nsi_2022_\"\n",
    "\n",
    "# List of states from 1 to 56 (max FIPS state code)\n",
    "states = [f\"{i:02d}\" for i in range(1, 57)]\n",
    "\n",
    "# Location to save the files\n",
    "location = os.path.join(data_path, \"state_gpkgs_zip\")\n",
    "\n",
    "# Loop through the states and download the files\n",
    "for i in states:\n",
    "    print(i)\n",
    "    # Construct the URL for the download\n",
    "    url = f\"{base_url}{i}.gpkg.zip\"\n",
    "    # Construct the file path to save the downloaded file\n",
    "    file_path = os.path.join(location, f\"nsi_2022_{i}.gpkg.zip\")\n",
    "    \n",
    "    try:\n",
    "        # Download the file\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "    except Exception as e:\n",
    "        # If there's an error, print it and continue\n",
    "        print(f\"Failed to download {url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unzip the structures\n",
    "unzipped_folder = os.path.join(data_path, \"state_gpkgs\")  \n",
    "os.makedirs(unzipped_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each ZIP file in the folder\n",
    "for zip_filename in os.listdir(location):\n",
    "    if zip_filename.endswith(\".zip\"):\n",
    "        zip_path = os.path.join(location, zip_filename)\n",
    "        \n",
    "        # Create a new folder to extract to (named after the zip file without the extension)\n",
    "        extract_folder = os.path.join(unzipped_folder, os.path.splitext(os.path.splitext(zip_filename)[0])[0])\n",
    "        os.makedirs(extract_folder, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # Extract the ZIP file to the new folder\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_folder)\n",
    "            print(f\"Successfully extracted: {zip_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract {zip_filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_abbreviation = {\n",
    "    '01': 'AL', '02': 'AK', '04': 'AZ', '05': 'AR', '06': 'CA', '08': 'CO', '09': 'CT', '10': 'DE', \n",
    "    '11': 'DC', '12': 'FL', '13': 'GA', '15': 'HI', '16': 'ID', '17': 'IL', '18': 'IN', '19': 'IA', \n",
    "    '20': 'KS', '21': 'KY', '22': 'LA', '23': 'ME', '24': 'MD', '25': 'MA', '26': 'MI', '27': 'MN', \n",
    "    '28': 'MS', '29': 'MO', '30': 'MT', '31': 'NE', '32': 'NV', '33': 'NH', '34': 'NJ', '35': 'NM', \n",
    "    '36': 'NY', '37': 'NC', '38': 'ND', '39': 'OH', '40': 'OK', '41': 'OR', '42': 'PA', '44': 'RI', \n",
    "    '45': 'SC', '46': 'SD', '47': 'TN', '48': 'TX', '49': 'UT', '50': 'VT', '51': 'VA', '53': 'WA', \n",
    "    '54': 'WV', '55': 'WI', '56': 'WY'\n",
    "}\n",
    "\n",
    "# Folder containing the GeoPackage files\n",
    "input_folder = os.path.join(data_path, \"state_gpkgs\") \n",
    "\n",
    "# Geodatabase to store the exported feature classes\n",
    "output_gdb = os.path.join(data_path, \"nsi_2022.gdb\")  \n",
    "arcpy.env.workspace = output_gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all feature classes in all GeoPackages\n",
    "feature_classes = []\n",
    "\n",
    "# Use arcpy.da.Walk() to iterate through the subfolders and locate all GeoPackage files\n",
    "for dirpath, dirnames, filenames in os.walk(input_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".gpkg\"):\n",
    "            # Full path to the GeoPackage file\n",
    "            gpkg_path = os.path.join(dirpath, filename)\n",
    "            \n",
    "            # Walk through the contents of the GeoPackage\n",
    "            walk = arcpy.da.Walk(gpkg_path)\n",
    "            for dirpath_gpkg, dirnames_gpkg, filenames_gpkg in walk:\n",
    "                for feature_class_name in filenames_gpkg:\n",
    "                    # Append the full path to the feature_classes list\n",
    "                    feature_classes.append(os.path.join(dirpath_gpkg, feature_class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_class_path in feature_classes:\n",
    "    # Extract the folder containing the GeoPackage (second deepest folder with the FIPS code)\n",
    "    parent_folder = os.path.splitext(os.path.basename(os.path.dirname(feature_class_path)))[0]  # Get \"nsi_2022_01\" from the path\n",
    "    \n",
    "    # Extract the FIPS code (assuming the format is \"nsi_2022_01\" -> \"01\")\n",
    "    fips_code = parent_folder.split(\"_\")[-1]\n",
    "    \n",
    "    # Check if the FIPS code exists in the dictionary\n",
    "    if fips_code in fips_to_abbreviation:\n",
    "        # Get the state abbreviation from the FIPS code\n",
    "        state_abbreviation = fips_to_abbreviation[fips_code]\n",
    "        \n",
    "        # Construct the new name for the feature class\n",
    "        new_feature_class_name = f\"{state_abbreviation}_nsi_2022\"\n",
    "\n",
    "        # convert and project to gdb\n",
    "        arcpy.FeatureClassToFeatureClass_conversion(feature_class_path, output_gdb, new_feature_class_name)\n",
    "        print(f\"Exported {feature_class_path} to {os.path.join(output_gdb, new_feature_class_name)}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"FIPS code {fips_code} not found in dictionary for {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
